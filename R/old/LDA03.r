## LDA analysis
library(MASS)
library(ggplot2)
require(gridExtra)
library(corrplot)

setwd("/home/pau/Projectes/dakd-project/R")

model.training <- function(x){
  lda.model2 <- lda(x$label ~ ., data=x[, !(names(x) %in% c('md5'))])
  return(lda.model2) 
}

model.predictor <- function(lda.model2, testData2){
  lda.prediction <- predict(object = lda.model2, newdata = testData2)
  dataset <- data.frame(label=lda.prediction$class, lda=lda.prediction$x, hash=testData2$md5,reallabel=testData2$label)
  return(dataset)
}

model.evaluation <- function(dataset){
  #accurate <- dataset[ which(dataset$reallabel == dataset$label), ]
  #nrow(accurate)
  errors <- dataset[ which(dataset$reallabel != dataset$label),]
  #print(nrow(errors))
  accuracy <- round(1 - nrow(errors)/nrow(dataset),4)
  accuracy <- nrow(errors)
  return(accuracy)
}

model.plotting <- function(dataset){
  
  p1 <- ggplot(dataset, aes(x=lda.LD1, y=lda.LD2, colour=label, shape=reallabel)) +
    geom_point() +
    coord_cartesian(ylim=c(-20,20),xlim=c(-50,50))
  
  p2 <- ggplot(dataset, aes(x=lda.LD1, y=lda.LD3, colour=label, shape=reallabel)) +
    geom_point() +
    coord_cartesian(ylim=c(-20,20),xlim=c(-50,50))
  
  p3 <- ggplot(dataset, aes(x=lda.LD1, y=lda.LD4, colour=label, shape=reallabel)) +
    geom_point() +
    coord_cartesian(ylim=c(-20,20),xlim=c(-50,50))
  
  p4 <- ggplot(dataset, aes(x=lda.LD2, y=lda.LD3, colour=label, shape=reallabel)) +
    geom_point() +
    coord_cartesian(ylim=c(-20,20),xlim=c(-50,50))
  
  p5 <- ggplot(dataset, aes(x=lda.LD2, y=lda.LD4, colour=label, shape=reallabel)) +
    geom_point() +
    coord_cartesian(ylim=c(-20,20),xlim=c(-50,50))
  
  p6 <- ggplot(dataset, aes(x=lda.LD3, y=lda.LD4, colour=label, shape=reallabel)) +
    geom_point() +
    coord_cartesian(ylim=c(-20,20),xlim=c(-25,25))
  
  grid.arrange(p1,p2,p3,p4,p5,p6)
  grid.arrange(p4,p6)
  p6
  
}

dataset.Stats <- function(x) {
  result <- table(x$label)
  l <- nrow(x)
  print(result)
  result <- round(result *100/l,2)
  print(result)
  #return(result)
}

fold.validation <- function(trainingSet, testingSet){
  drops <- c("name", "sha1", "sha256", "sha512")
  trainingSet <- trainingSet[, !(names(trainingSet) %in% drops)]
  testingSet <- testingSet[, !(names(testingSet) %in% drops)]
  
  #str(trainingSet)
  
  #print("training model...")
  mod <- model.training(trainingSet)
  #print("make the predictions...")
  result.set <- model.predictor(mod, testingSet)
  #print("computing accuracy...")
  accuracy.value <- model.evaluation(result.set)
  return(accuracy.value)
}

create.K.folds <- function(dataset, k ){
  n = nrow(dataset)
  fold.length = floor(n/k)
  fold <- list()
  for (i in 1:k){
    i1 <- (i-1)*fold.length + 1
    i2 <- i*fold.length
    if (i==k & i2 < n){
      i2 <- n
    }
    fold[[i]] <- dataset[c(i1:i2),]
    
    print(paste("fold rows",i1, i2))
    #print(head(colnames(dataset[c(i1:i2),])))
    #print(head(colnames(fold[[i]])))
  }
  
  return(fold)
}

create.stratified.proportional.K.folds <- function(dataset, k){
  
  # strategy 1: all class fold the same length (length of the smallest class fold)
  # strategy 2: all class fold their own length, but all folds with the same proportions
  # here: strategy 2
  
  n = nrow(dataset)
  fold.length = floor(n/k)
  fold <- list()
  
  labels <- levels(dataset$label)
  classes.length <- rep(1:length(labels))
  classes.fold.lengths <- rep(1:length(labels))
  classes.subsets <- list()
  # get elems in each label
  for (j in 1:length(labels)){
    # compute label.fold.length
    subset1 <- dataset[which(dataset$label == labels[j]),]
    classes.subsets[[j]] <- subset1
    l = nrow(subset1)
    kj = floor(l/k)
    #print(paste("subsetting for label",labels[j]," nrows",l," kfold length",kj))
    classes.length[j] <- l
    classes.fold.lengths[j] <- kj
       
  }
  
  for (i in 1:k){
    
    # create thenew fold as an empty data frame
    fold[[i]] <- dataset[0,]
    
    # for each class
    for (j in 1:length(classes.length)){
      # get the class fold length, 
      fold.length <- classes.fold.lengths[j]
      nj <- classes.length[j]
      
      i1 <- (i-1)*fold.length + 1
      i2 <- i*fold.length
      if (i==k & i2 < nj){
        i2 <- nj
      }
      
      #then add to the current fold
      fold[[i]] <- rbind(fold[[i]], classes.subsets[[j]][c(i1:i2),])
      
      #print(paste("fold ", i ," class", labels[j]," class legnth", nj, " class fold length", fold.length ," fold rows",i1, i2))
      #print(head(colnames(dataset[c(i1:i2),])))
      #print(head(colnames(fold[[i]])))
            
    }
    

  }
  
  return(fold)
}

create.stratified.equal.K.folds <- function(dataset, k){
  
  # strategy 1: all class fold the same length (length of the smallest class fold)
  # strategy 2: all class fold their own length, but all folds with the same proportions
  # here: strategy 1
  
  n = nrow(dataset)
  fold.length = floor(n/k)
  fold <- list()
  
  labels <- levels(dataset$label)
  classes.length <- rep(1:length(labels))
  classes.fold.lengths <- rep(1:length(labels))
  classes.subsets <- list()
  # get elems in each label
  for (j in 1:length(labels)){
    # compute label.fold.length
    subset1 <- dataset[which(dataset$label == labels[j]),]
    classes.subsets[[j]] <- subset1
    l = nrow(subset1)
    kj = floor(l/k)
    print(paste("subsetting for label",labels[j]," nrows",l," kfold length",kj))
    classes.length[j] <- l
    classes.fold.lengths[j] <- kj
    
  }
  
  # get the minimum of all labels for length and kfold length
  min.length = min(classes.length)
  min.fold.length = min(classes.fold.lengths)
  print(paste("min lengtn", min.length, "min fold lengt ", min.fold.length))
  
  for (i in 1:k){
    
    # create thenew fold as an empty data frame
    fold[[i]] <- dataset[0,]
    
    # for each class
    for (j in 1:length(classes.length)){
      # get the class fold length, 
      fold.length <- min.fold.length
      nj <- min.length
      
      i1 <- (i-1)*fold.length + 1
      i2 <- i*fold.length
      if (i==k & i2 < nj){
        i2 <- nj
      }
      
      #then add to the current fold
      fold[[i]] <- rbind(fold[[i]], classes.subsets[[j]][c(i1:i2),])
      
      print(paste("fold ", i ," class", labels[j]," class legnth", nj, " class fold length", fold.length ," fold rows",i1, i2))
      #print(head(colnames(dataset[c(i1:i2),])))
      #print(head(colnames(fold[[i]])))
    }
  }
  return(fold)
}


kfold.stratified.validation <- function(dataset){
  # divide test and training in K stratified folds
  k=10
  n=nrow(dataset)
  #fold <- create.K.folds(dataset, k, n)
  fold <- create.stratified.proportional.K.folds(dataset,k)
  #fold <- create.stratified.equal.K.folds(dataset,k)
 
  # compute  model and validation on each fold
  accuracies <- rep(0,k)
  for (i in 1:k){
    test.set = fold[[i]]
    
    #print("Test set:")
    #print(nrow(test.set))
    #print(head(names(test.set)))
    
    #print("training folds")
    training.set <- test.set[0,]
    if (i>1) {
      for (j in 1:(i-1) ){
        #print(paste(" i",i,"j",j))
        training.set <- rbind(training.set,fold[[j]])
        #print(nrow(training.set))
      }  
    }
    
    if (i < k ){
      for (j in (i+1):k){
        if (j <= k){
          #print(paste(" i",i,"j",j))
          training.set <- rbind(training.set,fold[[j]])
          #print(nrow(training.set))
        }
      }  
    }
    
    #print(head(fold))
    #print(paste("computing model for fold ",i))
    #print(nrow(training.set))
    #print(nrow(test.set))
    #print(head(names(training.set)))
    #print(head(names(test.set)))
    
    accuracies[i] <- fold.validation(training.set, test.set)
    #print(paste("----> accuracy",accuracies[i],"/",nrow(test.set)))
  }
  
  # return the average error or accuracy
  #return(accuracies)
  return(sum(accuracies)/n)
  
}

manual.cleaning <- function(csvData){
  #output <- csvData[ which(csvData$label != 'office' & csvData$label != 'tool' & csvData$label != 'banker'),]
  output <- csvData[ which(csvData$label != 'office' & csvData$label != 'tool' & csvData$label != 'safe' & csvData$label != 'banker'),]
  output$label <- factor(output$label)
  # clean empty columns after removed class!
  return(output)
}

pca.computation <- function(dataset, numcomp=30){
 
  PCA1 <- prcomp(dataset[,c(9:ncol(dataset))])
  
  pca.dataset <- data.frame(PCA1$x[,c(1:numcomp)])
  pca.dataset$name <- dataset$name
  pca.dataset$label <- dataset$label
  pca.dataset$md5 <- dataset$md5
  pca.dataset$sha1 <- dataset$sha1
  pca.dataset$sha256 <- dataset$sha256
  pca.dataset$sha512 <- dataset$sha512
  
  return(pca.dataset)
}


pca.computation.detailed <- function(dataset, numcomp=30){
  
  PCA1 <- prcomp(dataset[,c(9:ncol(dataset))])
  
  pca.dataset <- data.frame(PCA1$x[,c(1:numcomp)])
  pca.dataset$name <- dataset$name
  pca.dataset$label <- dataset$label
  pca.dataset$md5 <- dataset$md5
  pca.dataset$sha1 <- dataset$sha1
  pca.dataset$sha256 <- dataset$sha256
  pca.dataset$sha512 <- dataset$sha512
  
  return(pca.dataset)
}


pcaCharts <- function(x) {
  x.var <- x$sdev ^ 2
  x.pvar <- x.var/sum(x.var)
  print("proportions of variance:")
  print(x.pvar)
  
  par(mfrow=c(2,2))
  plot(x.pvar,xlab="Principal component", ylab="Proportion of variance explained", ylim=c(0,1), type='b')
  plot(cumsum(x.pvar),xlab="Principal component", ylab="Cumulative Proportion of variance explained", ylim=c(0,1), type='b')
  screeplot(x)
  screeplot(x,type="l")
  par(mfrow=c(1,1))
}

num.princomp.validation <- function(csvData2){
  accuracies <- c(rep(0,64))
  for (i in 1:64){
    accuracies[i] <- kfold.stratified.validation(pca.computation(csvData2,i))
    print(paste("num pca",i,"accuracy",accuracies[i]))
  }
  
  p1 <- plot(accuracies)
  p1
  return(accuracies)
}

# column means by class
plot.class.mean <- function(x, label) {
  
  drops <- c("X.1","X","name", "label", "sha256","sha512", "sha1", "md5")
  out.class <- x[(x$label == label),]
  out.class <- out.class[, !(names(out.class) %in% drops)]
  data=out.class
  plot(c(1:ncol(data)),colMeans(data))
  
  return(out.class)
}



# old data set------------------------------------------------------------
csvData <- read.csv(file="data_20171220.csv", header=TRUE, sep=",")

csvData2 <- manual.cleaning(csvData)
dataset.Stats(csvData2)
levels(csvData2$label)

eraseme <- kfold.stratified.validation(csvData2)
# error variables 1 2 13, ... appear to be constant within groups
eraseme

pca.dataset <- pca.computation(csvData2)
dataset.Stats(pca.dataset)
ncol(pca.dataset)
str(pca.dataset)

eraseme <- kfold.stratified.validation(pca.dataset) 
#eraseme <- fold.validation(pca.dataset[c(1:700),], pca.dataset[c(701:1400),])
eraseme

kfold.stratified.validation(pca.computation(csvData2,1))
kfold.stratified.validation(pca.computation(csvData2,2))
kfold.stratified.validation(pca.computation(csvData2,4))
kfold.stratified.validation(pca.computation(csvData2,8))
kfold.stratified.validation(pca.computation(csvData2,16))
kfold.stratified.validation(pca.computation(csvData2,32))
kfold.stratified.validation(pca.computation(csvData2,64))
kfold.stratified.validation(pca.computation(csvData2,128))

# validation or hyperparameter selection: choose the number of principal components
accuracies01 <- num.princomp.validation(csvData2)

# new dataset-------------------------------------------------------------------------
csvData.New <- read.csv(file="data_20171231.csv", header=TRUE, sep=",")

csvData2 <- manual.cleaning(csvData.New)
dataset.Stats(csvData2)
levels(csvData2$label)

#--- FDA suitability --------------


#removing X.1,X,label and hashes columns! only the name 
drops <- c("X.1","X","name", "label", "sha256","sha512", "sha1", "md5")
csvData3 <- csvData2[, !(names(csvData2) %in% drops)]

colnames(csvData3) <- c(1:ncol(csvData3))
describe(csvData3)
head(csvData3[,c(1:10)])

M<-cor(csvData3)
head(round(M,2))
corrplot(M[c(1:100), c(1:100)], method="circle")
corrplot(M[c(1:100), c(1:100)], type="upper", order="hclust", col=c("black", "white"),
         bg="lightblue")
corrplot(M[c(1:15), c(1:15)], method="number")
corrplot(M[c(250:265), c(250:265)], method="number")

# eval cov

# means of several columns
head(csvData3[c(200,204),c(41:60)])
colMeans(csvData3)
data=csvData3
plot(c(1:ncol(data)),colMeans(data))
data=csvData3[,c(200:213)]
plot(c(1:ncol(data)),colMeans(data))


trojan.class <- plot.class.mean(csvData2,"trojan")
adware.class <- plot.class.mean(csvData2,"adware")
ransomware.class <- plot.class.mean(csvData2,"ransomware")
downloader.class <- plot.class.mean(csvData2,"downloader")
malicious.class <- plot.class.mean(csvData2,"malicious")
unknown.class <- plot.class.mean(csvData2,"unknown")

cov.trojan <- cov(trojan.class)
cov.trojan[c(1:10),c(1:10)]
cor.trojan <- cor(trojan.class)
cor.trojan[c(1:10),c(1:10)]
library(matrixcalc)
is.diagonal.matrix(cor.trojan)
is.diagonal.matrix(cov.trojan)

var.trojan <- var(trojan.class)


# sample variances

# eigenvalues eigenvectors
ev <- eigen(csvData3[c(1:100),c(1:100)])
ev



#----PCA transformation------------------
eraseme <- kfold.stratified.validation(csvData2)
# error variables 1 2 13, ... appear to be constant within groups
eraseme

pca.dataset <- pca.computation(csvData2)
pcaCharts(pca.dataset)
names(pca.dataset)
dataset.Stats(pca.dataset)

ncol(pca.dataset)
str(pca.dataset)

# reeval correlation
drops <- c("X.1","X","name", "label", "sha256","sha512", "sha1", "md5")
pcaData3 <- pca.dataset[, !(names(pca.dataset) %in% drops)]
colnames(pcaData3) <- c(1:ncol(pcaData3))
M<-cor(pcaData3)
ncol(pcaData3)
corrplot(M, method="circle")
corrplot(M[c(1:10), c(1:10)], type="upper", order="hclust", col=c("black", "white"),
         bg="lightblue")
corrplot(M[c(1:15), c(1:15)], method="number")

head(pcaData3)

#reeval class means
trojan.class <- plot.class.mean(pca.dataset,"trojan")
adware.class <- plot.class.mean(pca.dataset,"adware")
ransomware.class <- plot.class.mean(pca.dataset,"ransomware")
downloader.class <- plot.class.mean(pca.dataset,"downloader")
malicious.class <- plot.class.mean(pca.dataset,"malicious")
unknown.class <- plot.class.mean(pca.dataset,"unknown")


eraseme <- kfold.stratified.validation(pca.dataset) 
#eraseme <- fold.validation(pca.dataset[c(1:700),], pca.dataset[c(701:1400),])
eraseme






# ------Validation----------------------
# validation or hyperparameter selection: choose the number of principal components
accuracies02 <- num.princomp.validation(csvData2)




#--------------------------------------------------------------------------------------------


# PCA tests
ncol(csvData) - 7
head(csvData[,c(8:ncol(csvData))])
PCA1 <- prcomp(csvData[,c(8:ncol(csvData))])
d1PCA <- PCA1$x[,1]
PCA1
PCA1$x
colnames(PCA1$x[,c(1:30)])
PCA1$center
PCA1$sdev
par(mfrow=c(1))
dim(PCA1$x)
biplot(PCA1, scale = 0)
warnings()
PCA1$x[,c(1:4)]
pca.dataset <- data.frame(PCA1$x[,c(1:30)])
pca.dataset$label <- csvData$label
pca.dataset$name <- csvData$name
pca.dataset$md5 <- csvData$md5
head(pca.dataset)


#colnames(csvData)
#dataset.Stats(csvData)
csvData2 <- manual.cleaning(csvData)
#levels(csvData$label)
#levels(csvData2$label)
#dataset.Stats(csvData2)
create.stratified.K.folds(csvData,10, length(csvData))

eraseme <- create.stratified.proportional.K.folds(csvData2,10)
print(nrow(eraseme[[9]]))
dataset.Stats(eraseme[[1]])
dataset.Stats(eraseme[[4]])
dataset.Stats(eraseme[[7]])
dataset.Stats(eraseme[[10]])

csvData3 <- csvData2[ which( csvData2$label != 'ransomware'),]
csvData3$label <- factor(csvData3$label)
levels(csvData3$label)
dataset.Stats(csvData3)
eraseme <- create.stratified.equal.K.folds(csvData3,10)
print(nrow(eraseme[[9]]))
dataset.Stats(eraseme[[1]])
dataset.Stats(eraseme[[4]])
dataset.Stats(eraseme[[7]])
dataset.Stats(eraseme[[10]])


#eraseme <- kfold.stratified.validation(csvData)

trainData <- csvData[c(1:99,200:600,1100:1326),]
testData <- csvData[c(100:200,600:1100,1327:1426),]
dataset.Stats(trainData)
dataset.Stats(testData)


mod <- model.training(trainData)
result.set <- model.predictor(mod, testData)
model.evaluation(result.set)
model.plotting(result.set)




# data cleaning 
#  empty groups -> filter out
#  test with 2, 3 main classes

# data mining alg:
# FDA is not suitable for sparse interger matrix
# 0) percentages? -> real number + somehow reduce sparsity
# 1) iterar els pca's creant clasif fins que rendiment baixi ( # 30ena  i reals)
# 2) embedding (software: gensim embedding)
# 3) svm
# 4) psa
